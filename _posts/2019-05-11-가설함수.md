---
layout: article

title: 모델 표현, 가설 함수

tags: machine-learning coursera week1

sidebar:

​	nav: layout

mathjax: true
---



# 한가지 변수를 가진 선형회귀(Linear Regression)

## 모델 표현(Model Representation)

*회귀문제* 에서 우리는 입력값을 이용하여 *연속적인* 결과 함수로 우리의 결과값을 표현하려 하였습니다. 

하나의 변수를 사용한 선형 회귀는 "단 변량 선형 회귀 (univariate linear regression)"로도 알려져 있습니다.

단 변량 선형 회귀는 **단일 입력** 값 x 에서 **단일 출력** 값 y 를 예측하려는 경우에 사용됩니다 . 우리는 여기서 **감독 학습**을 하고 있습니다. 그 말의 뜻은 우리는 이미 입출력의 원인과 결과값이 어떠할지 예상할 수 있다는 것을 의미합니다.

## 가설 함수(The Hypothesis Function)

가설 함수는 일반적으로 다음과 같습니다.
$\hat{y} = h_\theta(x) = \theta_0 + \theta_1 x$
이것은 직선 방정식(1차 방정식)과 같습니다. 우리는 결과값$\hat{y}$ 를 예측하기 위해 $h_\theta (x)$ $\theta_0$ 과 $\theta_1$ 에 대한  우리의 예상 생산량을 얻으려면 즉, 우리는 입력 데이터 (x)를 출력 데이터 (y)에 매핑 가능한 함수, $h_\theta$를 생성하려고합니다.

### 예:

다음과 같은 일련의 학습 데이터가 있다고 가정 해보십시오.

| 입력값 x | 출력값 y |
| -------- | -------- |
| 0        | 4        |
| 1        | 7        |
| 2        | 7        |
| 3        | 8        |

이제 우리의 $h_\theta$ 함수에 대해 $\theta_0 = 2$ 와 $\theta_1 = 2$ 로 추측을 할 수 있습니다.   이때 가설 함수는 $h_\theta (x) = 2 + 2x$ 가 됩니다.

그래서 우리 가설함수에 1을 대입하면 y는 4가 될 것입니다. 이것은 실제값과 3정도 차이가 납니다.  그래서 우리는 x-y 평면에 매핑 된 데이터 점을 통해 가능한 가장 "적합"하거나 가장 대표적인 "직선"을 제공하는 값을 찾기 위해 여러가지 $\theta_0$ , $\theta_1$ 값을 테스트 해 볼 것입니다.